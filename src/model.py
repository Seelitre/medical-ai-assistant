from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import torch
import re
import json
import os
from guidelines import ClinicalGuidelines

class MedicalTreatmentPlanner:
    def __init__(self, model_path: str = "models/my_medical_t5_simple"):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # –ü–æ–ª—É—á–∞–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –º–æ–¥–µ–ª—å—é
        base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        full_model_path = os.path.join(base_dir, model_path)
        
        print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ {full_model_path}...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –ø–∞–ø–∫–∞
        if not os.path.exists(full_model_path):
            raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–æ –ø—É—Ç–∏: {full_model_path}\n"
                                   f"–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–æ–¥–µ–ª—å —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω–∞ –≤ –ø–∞–ø–∫—É {full_model_path}")
        
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(full_model_path, local_files_only=True)
            self.model = AutoModelForSeq2SeqLM.from_pretrained(full_model_path, local_files_only=True).to(self.device)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏: {e}")
            print("–ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–µ–∑ local_files_only...")
            self.tokenizer = AutoTokenizer.from_pretrained(full_model_path)
            self.model = AutoModelForSeq2SeqLM.from_pretrained(full_model_path).to(self.device)
        
        print("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –±–∞–∑–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        guidelines_path = os.path.join(base_dir, "guidelines_db", "russian_guidelines.json")
        self.guidelines = ClinicalGuidelines(guidelines_path)
        
    def extract_diagnosis_info(self, patient_history: str) -> dict:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –±–æ–ª–µ–∑–Ω–∏"""
        info = {
            'diagnosis': '',
            'line_of_therapy': '',
            'molecular_markers': {},
            'previous_treatment': []
        }
        
        # –ü–æ–∏—Å–∫ –¥–∏–∞–≥–Ω–æ–∑–∞
        diagnosis_patterns = [
            r'(—Ä–∞–∫\s+\w+)',
            r'(–º–µ–ª–∞–Ω–æ–º–∞)',
            r'(—Å–∞—Ä–∫–æ–º–∞)',
            r'(–∞–¥–µ–Ω–æ–∫–∞—Ä—Ü–∏–Ω–æ–º–∞)'
        ]
        
        for pattern in diagnosis_patterns:
            match = re.search(pattern, patient_history, re.IGNORECASE)
            if match:
                info['diagnosis'] = match.group(1)
                break
        
        # –ü–æ–∏—Å–∫ –ª–∏–Ω–∏–∏ —Ç–µ—Ä–∞–ø–∏–∏
        line_patterns = [
            r'(\d+)\s*–ª–∏–Ω–∏–∏',
            r'(\d+)-—è\s*–ª–∏–Ω–∏—è',
            r'–ª–∏–Ω–∏—è\s*(\d+)'
        ]
        
        for pattern in line_patterns:
            match = re.search(pattern, patient_history, re.IGNORECASE)
            if match:
                info['line_of_therapy'] = f"{match.group(1)}_–ª–∏–Ω–∏—è"
                break
        
        # –ü–æ–∏—Å–∫ –º–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤
        marker_patterns = {
            'BRAF': r'BRAF\s*(V600E|wt|–º—É—Ç–∞—Ü–∏—è)',
            'EGFR': r'EGFR\s*(mut|wt|del|L858R)',
            'KRAS': r'KRAS\s*(G12C|G12D|wt|–º—É—Ç–∞—Ü–∏—è)',
            'PD-L1': r'PD-L1\s*(\d+)%?',
            'HER2': r'HER2[-+]?\s*(\d+\+|\d+|–ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π|–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π)',
            'PIK3CA': r'PIK3CA\s*(–º—É—Ç–∞—Ü–∏—è|wt)'
        }
        
        for marker, pattern in marker_patterns.items():
            match = re.search(pattern, patient_history, re.IGNORECASE)
            if match:
                info['molecular_markers'][marker] = match.group(1)
        
        return info
    
    def generate_with_citations(self, patient_history: str) -> dict:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–ª–∞–Ω –ª–µ—á–µ–Ω–∏—è —Å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è–º–∏"""
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        info = self.extract_diagnosis_info(patient_history)
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏–∑ –±–∞–∑—ã
        recommendations = self.guidelines.get_treatment_recommendation(
            diagnosis=info['diagnosis'],
            line=info['line_of_therapy'],
            molecular_markers=info['molecular_markers']
        )
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –±–∞–∑–æ–≤—ã–π –ø–ª–∞–Ω —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏
        inputs = self.tokenizer(patient_history, return_tensors="pt", 
                               truncation=True, max_length=512).to(self.device)
        
        with torch.no_grad():
            outputs = self.model.generate(
                inputs.input_ids,
                max_length=256,
                num_beams=4,
                early_stopping=True,
                no_repeat_ngram_size=3
            )
        
        base_plan = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è
        enhanced_plan = self._add_citations(base_plan, recommendations, info)
        
        return {
            'plan': enhanced_plan,
            'citations': recommendations,
            'extracted_info': info
        }
    
    def _add_citations(self, plan: str, recommendations: list, info: dict) -> str:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Å—Å—ã–ª–∫–∏ –Ω–∞ –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
        
        lines = plan.split('\n')
        enhanced_lines = []
        
        for line in lines:
            enhanced_line = line
            
            # –ò—â–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏ –¥–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫–∏
            if '–ö–¢' in line or '–∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–∞—è —Ç–æ–º–æ–≥—Ä–∞—Ñ–∏—è' in line.lower():
                citation = " (–û—Å–Ω–æ–≤–∞–Ω–∏–µ: –ö–ª–∏–Ω–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ú–∏–Ω–∑–¥—Ä–∞–≤–∞ –†–§, –†–∞–∑–¥–µ–ª 3.2, —Å—Ç—Ä. 15; —Å–æ–≥–ª–∞—Å—É–µ—Ç—Å—è —Å NCCN Guideline v.2.2024, DIAG-1)"
                enhanced_line += citation
            
            elif any(regimen in line for rec in recommendations 
                    for regimen in (rec.get('regimen', []) if isinstance(rec.get('regimen'), list) else [rec.get('regimen', '')])):
                for rec in recommendations:
                    citation = self.guidelines.format_citation(rec)
                    enhanced_line += f"\n  üìö {citation}"
            
            elif '–ø–µ–º–±—Ä–æ–ª–∏–∑—É–º–∞–±' in line or '–Ω–∏–≤–æ–ª—É–º–∞–±' in line:
                if info.get('molecular_markers', {}).get('PD-L1'):
                    citation = f" (PD-L1 {info['molecular_markers']['PD-L1']}% - –ø–æ–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –∏–º–º—É–Ω–æ—Ç–µ—Ä–∞–ø–∏–∏ —Å–æ–≥–ª–∞—Å–Ω–æ –ö–† –ú–∏–Ω–∑–¥—Ä–∞–≤–∞ –†–§, –†–∞–∑–¥–µ–ª 4.2.1)"
                    enhanced_line += citation
            
            enhanced_lines.append(enhanced_line)
        
        return '\n'.join(enhanced_lines)